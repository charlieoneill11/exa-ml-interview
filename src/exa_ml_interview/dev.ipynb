{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesoneill/miniconda3/envs/exa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import List\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    document_id: str\n",
    "    document_text: str\n",
    "    score: float\n",
    "\n",
    "class RandomRetriever:\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def search(self, query: str, k: int) -> List[Result]:\n",
    "        results = random.sample(list(self.corpus.items()), k)\n",
    "        return [Result(doc_id, text, random.random()) for doc_id, text in results]\n",
    "\n",
    "def evaluate_retriever(retriever, queries, corpus, k=1, num_queries=1000):\n",
    "    correct = 0\n",
    "    total_time = 0\n",
    "\n",
    "    for query, relevant_docs in queries[:num_queries]:\n",
    "        start_time = time.time()\n",
    "        results = retriever.search(query, k)\n",
    "        end_time = time.time()\n",
    "\n",
    "        total_time += end_time - start_time\n",
    "\n",
    "        if any(result.document_id in relevant_docs for result in results):\n",
    "            correct += 1\n",
    "\n",
    "    recall_at_k = correct / num_queries\n",
    "    avg_time = total_time / num_queries\n",
    "\n",
    "    return recall_at_k, avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 18.7M/18.7M [00:01<00:00, 10.9MB/s]\n",
      "Downloading data: 100%|██████████| 265k/265k [00:00<00:00, 1.46MB/s]\n",
      "Downloading data: 100%|██████████| 292k/292k [00:00<00:00, 1.04MB/s]\n",
      "Generating train split: 100%|██████████| 284212/284212 [00:00<00:00, 6649958.32 examples/s]\n",
      "Generating dev split: 100%|██████████| 4009/4009 [00:00<00:00, 1416474.16 examples/s]\n",
      "Generating dev2 split: 100%|██████████| 4411/4411 [00:00<00:00, 1694547.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "corpus = load_dataset(\"mteb/msmarco-v2\", \"corpus\")\n",
    "queries = load_dataset(\"mteb/msmarco-v2\", \"queries\")\n",
    "default = load_dataset(\"mteb/msmarco-v2\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['query-id', 'corpus-id', 'score'],\n",
       "        num_rows: 284212\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['query-id', 'corpus-id', 'score'],\n",
       "        num_rows: 4009\n",
       "    })\n",
       "    dev2: Dataset({\n",
       "        features: ['query-id', 'corpus-id', 'score'],\n",
       "        num_rows: 4411\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    corpus: Dataset({\n",
       "        features: ['_id', 'title', 'text'],\n",
       "        num_rows: 138364198\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    queries: Dataset({\n",
       "        features: ['_id', 'text'],\n",
       "        num_rows: 285328\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated and saved 1000 evaluation queries to eval_queries.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Get dev set from default dataset\n",
    "dev_set = default['dev']\n",
    "\n",
    "# Create a dictionary of query_id to query_text\n",
    "query_dict = {q['_id']: q['text'] for q in queries['queries']}\n",
    "\n",
    "# Create a list to store our evaluation queries\n",
    "eval_queries = []\n",
    "\n",
    "# Use set for faster lookup\n",
    "used_query_ids = set()\n",
    "\n",
    "# Randomly sample from dev set until we have 1000 unique queries\n",
    "while len(eval_queries) < 1000:\n",
    "    idx = random.randint(0, len(dev_set) - 1)\n",
    "    query_id = dev_set[idx]['query-id']\n",
    "    \n",
    "    if query_id not in used_query_ids and query_id in query_dict:\n",
    "        used_query_ids.add(query_id)\n",
    "        eval_queries.append({\n",
    "            'query_id': query_id,\n",
    "            'query_text': query_dict[query_id],\n",
    "            'relevant_doc_id': dev_set[idx]['corpus-id']\n",
    "        })\n",
    "\n",
    "# Save the evaluation queries to a JSON file\n",
    "with open('eval_queries.json', 'w') as f:\n",
    "    json.dump(eval_queries, f)\n",
    "\n",
    "print(f\"Generated and saved {len(eval_queries)} evaluation queries to eval_queries.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Sampling 20.0% of the corpus...\n",
      "Sampled corpus size: 27672839\n",
      "Loading or creating corpus ID to index mapping...\n",
      "Creating new corpus ID to index mapping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3886934/27672839 [15:23<1:34:10, 4209.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     64\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(data, f)\n\u001b[0;32m---> 66\u001b[0m train_data, corpus_id_to_index \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m save_data(train_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m save_data(corpus_id_to_index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus_id_to_index.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[78], line 31\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating new corpus ID to index mapping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     corpus_id_to_index \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus_id_to_index.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     33\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(corpus_id_to_index, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/arrow_dataset.py:2455\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2454\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[0;32m-> 2455\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2457\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/arrow_dataset.py:2851\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2849\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2850\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2851\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:397\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:437\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 437\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:145\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "CORPUS_FRACTION = 0.2  # Fraction of corpus to load\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def prepare_data():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    corpus = load_dataset(\"mteb/msmarco-v2\", \"corpus\")['corpus']\n",
    "    queries = load_dataset(\"mteb/msmarco-v2\", \"queries\")['queries']\n",
    "    train = load_dataset(\"mteb/msmarco-v2\", \"default\", split=\"train\")\n",
    "\n",
    "    print(f\"Sampling {CORPUS_FRACTION:.1%} of the corpus...\")\n",
    "    corpus_sample_size = int(len(corpus) * CORPUS_FRACTION)\n",
    "    corpus_sample = corpus.shuffle(seed=RANDOM_SEED).select(range(corpus_sample_size))\n",
    "    print(f\"Sampled corpus size: {len(corpus_sample)}\")\n",
    "\n",
    "    print(\"Loading or creating corpus ID to index mapping...\")\n",
    "    if os.path.exists('corpus_id_to_index.json'):\n",
    "        with open('corpus_id_to_index.json', 'r') as f:\n",
    "            corpus_id_to_index = json.load(f)\n",
    "        print(\"Loaded existing corpus ID to index mapping.\")\n",
    "    else:\n",
    "        print(\"Creating new corpus ID to index mapping...\")\n",
    "        corpus_id_to_index = {item['_id']: idx for idx, item in enumerate(tqdm(corpus_sample))}\n",
    "        with open('corpus_id_to_index.json', 'w') as f:\n",
    "            json.dump(corpus_id_to_index, f)\n",
    "        print(\"Created and saved new corpus ID to index mapping.\")\n",
    "\n",
    "    print(\"Filtering training data to match sampled corpus...\")\n",
    "    train_filtered = train.filter(lambda x: x['corpus-id'] in corpus_id_to_index)\n",
    "    \n",
    "    print(f\"Filtered training data size: {len(train_filtered)}\")\n",
    "\n",
    "    print(\"Creating query ID to index mapping...\")\n",
    "    query_ids = set(train_filtered['query-id'])\n",
    "    queries_filtered = queries.filter(lambda x: x['_id'] in query_ids)\n",
    "    queries_id_to_index = {item['_id']: idx for idx, item in enumerate(queries_filtered)}\n",
    "\n",
    "    print(\"Preparing final training data...\")\n",
    "    train_data = []\n",
    "    for item in tqdm(train_filtered, desc=\"Processing training examples\"):\n",
    "        query_id = item['query-id']\n",
    "        doc_id = item['corpus-id']\n",
    "        \n",
    "        query = queries_filtered[queries_id_to_index[query_id]]['text']\n",
    "        positive_doc = corpus_sample[corpus_id_to_index[doc_id]]['text']\n",
    "\n",
    "        train_data.append({\n",
    "            'query': query,\n",
    "            'positive': positive_doc\n",
    "        })\n",
    "\n",
    "    return train_data, corpus_id_to_index\n",
    "\n",
    "def save_data(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "train_data, corpus_id_to_index = prepare_data()\n",
    "save_data(train_data, 'train_data.json')\n",
    "save_data(corpus_id_to_index, 'corpus_id_to_index.json')\n",
    "print(f\"Saved {len(train_data)} training examples to train_data.json\")\n",
    "print(f\"Saved corpus ID to index mapping with {len(corpus_id_to_index)} entries to corpus_id_to_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "CORPUS_FRACTION = 0.1  # Fraction of corpus to load\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def prepare_data():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    corpus = load_dataset(\"mteb/msmarco-v2\", \"corpus\")['corpus']\n",
    "    queries = load_dataset(\"mteb/msmarco-v2\", \"queries\")['queries']\n",
    "    train = load_dataset(\"mteb/msmarco-v2\", \"default\", split=\"train\") #split=\"train\")\n",
    "\n",
    "    print(f\"Sampling {CORPUS_FRACTION:.1%} of the corpus...\")\n",
    "    corpus_sample_size = int(len(corpus) * CORPUS_FRACTION)\n",
    "    corpus_sample = corpus.shuffle(seed=RANDOM_SEED).select(range(corpus_sample_size))\n",
    "    print(f\"Sampled corpus size: {len(corpus_sample)}\")\n",
    "\n",
    "    print(\"Creating corpus ID to index mapping...\")\n",
    "    corpus_id_to_index = {item['_id']: idx for idx, item in enumerate(tqdm(corpus_sample))}\n",
    "\n",
    "    # Save corpus_id to index\n",
    "    with open('corpus_id_to_index.json', 'w') as f:\n",
    "        json.dump(corpus_id_to_index, f)\n",
    "\n",
    "    print(\"Filtering training data to match sampled corpus...\")\n",
    "    train_filtered = train.filter(lambda x: x['corpus-id'] in corpus_id_to_index)\n",
    "    \n",
    "    print(f\"Filtered training data size: {len(train_filtered)}\")\n",
    "\n",
    "    print(\"Creating query ID to index mapping...\")\n",
    "    query_ids = set(train_filtered['query-id'])\n",
    "    queries_filtered = queries.filter(lambda x: x['_id'] in query_ids)\n",
    "    queries_id_to_index = {item['_id']: idx for idx, item in enumerate(queries_filtered)}\n",
    "\n",
    "    print(\"Preparing final training data...\")\n",
    "    train_data = []\n",
    "    for item in tqdm(train_filtered, desc=\"Processing training examples\"):\n",
    "        query_id = item['query-id']\n",
    "        doc_id = item['corpus-id']\n",
    "        \n",
    "        query = queries_filtered[queries_id_to_index[query_id]]['text']\n",
    "        positive_doc = corpus_sample[corpus_id_to_index[doc_id]]['text']\n",
    "\n",
    "        # negs\n",
    "        negative_indices = random.sample(range(len(corpus_sample)), 3)  # 3 negs\n",
    "        negative_docs = [corpus_sample[i]['text'] for i in negative_indices]\n",
    "\n",
    "        train_data.append({\n",
    "            'query': query,\n",
    "            'positive': positive_doc,\n",
    "            'negatives': negative_docs\n",
    "        })\n",
    "\n",
    "    return train_data\n",
    "\n",
    "def save_data(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Loading datasets...\n",
      "Sampling 10.0% of the corpus...\n",
      "Sampled corpus size: 13836419\n",
      "Creating corpus ID to index mapping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 349874/13836419 [01:11<45:43, 4916.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsmarco_train_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[67], line 24\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled corpus size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(corpus_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating corpus ID to index mapping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m corpus_id_to_index \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Save corpus_id to index\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus_id_to_index.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/arrow_dataset.py:2455\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2454\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[0;32m-> 2455\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2457\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/arrow_dataset.py:2851\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2849\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2850\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2851\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:397\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:437\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 437\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/datasets/formatting/formatting.py:145\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "train_data = prepare_data()\n",
    "\n",
    "print(f\"Sampled {len(train_data)} examples.\")\n",
    "\n",
    "filename = 'msmarco_train_data.json'\n",
    "save_data(train_data, filename)\n",
    "print(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting random seed for reproducibility...\n",
      "Loading datasets...\n",
      "Sampling 1.0% of the corpus...\n",
      "Creating corpus ID to index mapping...\n",
      "Time taken: 291.46s\n",
      "Filtering dev data to match sampled corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4009/4009 [00:00<00:00, 307274.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dev data size: 33\n",
      "Sampling up to 1000 dev examples...\n",
      "Preparing final dev data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 633077.37 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 652613.60 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 644402.64 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 653765.49 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 660105.63 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 638986.66 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 650428.69 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 649878.75 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 657113.96 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 653352.18 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 657563.84 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 656709.74 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 650251.99 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 657204.54 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 658360.03 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 655240.94 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 655258.88 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 654108.16 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 634627.71 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 656518.08 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 652338.97 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 651396.61 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 653991.63 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 641303.09 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 647239.88 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 613679.83 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 653311.52 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 661536.37 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 658633.58 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 636707.91 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 630815.89 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 631920.75 examples/s]\n",
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 630748.73 examples/s]\n",
      "Processing dev examples: 100%|██████████| 33/33 [00:14<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Constants\n",
    "CORPUS_FRACTION = 0.01  # Fraction of corpus to load\n",
    "RANDOM_SEED = 42\n",
    "DEV_SIZE = 1000\n",
    "\n",
    "def prepare_dev_data():\n",
    "    print(\"Setting random seed for reproducibility...\")\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    corpus = load_dataset(\"mteb/msmarco-v2\", \"corpus\")['corpus']\n",
    "    queries = load_dataset(\"mteb/msmarco-v2\", \"queries\")['queries']\n",
    "    dev = load_dataset(\"mteb/msmarco-v2\", \"default\", split=\"dev\")\n",
    "\n",
    "    print(f\"Sampling {CORPUS_FRACTION:.1%} of the corpus...\")\n",
    "    corpus_sample_size = int(len(corpus) * CORPUS_FRACTION)\n",
    "    corpus_sample = corpus.shuffle(seed=RANDOM_SEED).select(range(corpus_sample_size))\n",
    "\n",
    "    print(\"Creating corpus ID to index mapping...\")\n",
    "    start = time.time()\n",
    "    corpus_id_to_index = {item['_id']: idx for idx, item in enumerate(corpus_sample)}\n",
    "    end = time.time()\n",
    "    print(f\"Time taken: {end - start:.2f}s\")\n",
    "\n",
    "    print(\"Filtering dev data to match sampled corpus...\")\n",
    "    dev_filtered = dev.filter(lambda x: x['corpus-id'] in corpus_id_to_index)\n",
    "    \n",
    "    print(f\"Filtered dev data size: {len(dev_filtered)}\")\n",
    "\n",
    "    print(f\"Sampling up to {DEV_SIZE} dev examples...\")\n",
    "    dev_sample = dev_filtered.shuffle(seed=RANDOM_SEED).select(range(min(DEV_SIZE, len(dev_filtered))))\n",
    "\n",
    "    print(\"Preparing final dev data...\")\n",
    "    dev_data = []\n",
    "    for item in tqdm(dev_sample, desc=\"Processing dev examples\"):\n",
    "        query_id = item['query-id']\n",
    "        doc_id = item['corpus-id']\n",
    "        \n",
    "        query = queries.filter(lambda x: x['_id'] == query_id)[0]['text']\n",
    "        positive_doc = corpus_sample[corpus_id_to_index[doc_id]]['text']\n",
    "\n",
    "        # Sample negative documents\n",
    "        negative_indices = random.sample(range(len(corpus_sample)), 3)  # 3 negative samples\n",
    "        negative_docs = [corpus_sample[i]['text'] for i in negative_indices]\n",
    "\n",
    "        dev_data.append({\n",
    "            'query': query,\n",
    "            'positive': positive_doc,\n",
    "            'negatives': negative_docs\n",
    "        })\n",
    "\n",
    "    return dev_data\n",
    "\n",
    "def save_data(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "# train_data = prepare_data()\n",
    "dev_data = prepare_dev_data()\n",
    "\n",
    "# save_data(train_data, 'msmarco_train_data.json')\n",
    "save_data(dev_data, 'msmarco_dev_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 dev examples.\n",
      "Loaded 2833 train examples.\n"
     ]
    }
   ],
   "source": [
    "# Load dev data and train data\n",
    "with open('msmarco_dev_data.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open('msmarco_train_data.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Print length of both\n",
    "print(f\"Loaded {len(dev_data)} dev examples.\")\n",
    "print(f\"Loaded {len(train_data)} train examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple bi-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device and random seed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 8\n",
    "ACCURACY_INTERVAL = 10\n",
    "\n",
    "class BiEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return F.normalize(outputs.pooler_output, p=2, dim=-1)\n",
    "\n",
    "def load_prepared_data(filename):\n",
    "    print(f\"Loading prepared data from {filename}...\")\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Loaded {len(data)} examples.\")\n",
    "    return data\n",
    "\n",
    "def tokenize_batch(batch, tokenizer):\n",
    "    queries = tokenizer([item['query'] for item in batch], padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    documents = tokenizer([item['positive'] for item in batch], padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    \n",
    "    # Remove token_type_ids from all tokenized outputs\n",
    "    for output in [queries, documents]:\n",
    "        output.pop('token_type_ids', None)\n",
    "\n",
    "    return {\n",
    "        'queries': {k: v.to(device) for k, v in queries.items()},\n",
    "        'documents': {k: v.to(device) for k, v in documents.items()}\n",
    "    }\n",
    "\n",
    "def in_batch_cross_entropy_loss(similarities):\n",
    "    labels = torch.arange(similarities.size(0)).to(device)\n",
    "    return nn.CrossEntropyLoss()(similarities, labels)\n",
    "\n",
    "def recall_at_1(similarities):\n",
    "    return (similarities.argmax(dim=1) == torch.arange(similarities.size(0)).to(device)).float().mean().item()\n",
    "\n",
    "def evaluate(model, data, tokenizer):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    recalls = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), BATCH_SIZE):\n",
    "            batch = data[i:i+BATCH_SIZE]\n",
    "            tokenized_batch = tokenize_batch(batch, tokenizer)\n",
    "            \n",
    "            query_embeddings = model(**tokenized_batch['queries'])\n",
    "            doc_embeddings = model(**tokenized_batch['documents'])\n",
    "            \n",
    "            similarities = torch.mm(query_embeddings, doc_embeddings.t())\n",
    "            \n",
    "            loss = in_batch_cross_entropy_loss(similarities)\n",
    "            recall = recall_at_1(similarities)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            recalls.append(recall)\n",
    "    \n",
    "    return sum(losses) / len(losses), sum(recalls) / len(recalls)\n",
    "\n",
    "def train_and_evaluate():\n",
    "    model = BiEncoder().to(device)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    train_data = load_prepared_data('msmarco_train_data.json')\n",
    "    dev_data = load_prepared_data('msmarco_dev_data.json')\n",
    "    \n",
    "    train_losses = []\n",
    "    train_recalls = []\n",
    "    dev_losses = []\n",
    "    dev_recalls = []\n",
    "    \n",
    "    for epoch in range(3):  # 3 epochs\n",
    "        model.train()\n",
    "        random.shuffle(train_data)  # Shuffle data at the start of each epoch\n",
    "        for i in tqdm(range(0, len(train_data), BATCH_SIZE), desc=f\"Epoch {epoch+1}\"):\n",
    "            batch = train_data[i:i+BATCH_SIZE]\n",
    "            tokenized_batch = tokenize_batch(batch, tokenizer)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            query_embeddings = model(**tokenized_batch['queries'])\n",
    "            doc_embeddings = model(**tokenized_batch['documents'])\n",
    "            \n",
    "            similarities = torch.mm(query_embeddings, doc_embeddings.t())\n",
    "            \n",
    "            loss = in_batch_cross_entropy_loss(similarities)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_recalls.append(recall_at_1(similarities))\n",
    "            \n",
    "            #if i % (ACCURACY_INTERVAL * BATCH_SIZE) == 0:\n",
    "            avg_train_loss = sum(train_losses[-ACCURACY_INTERVAL:]) / min(ACCURACY_INTERVAL, len(train_losses))\n",
    "            avg_train_recall = sum(train_recalls[-ACCURACY_INTERVAL:]) / min(ACCURACY_INTERVAL, len(train_recalls))\n",
    "            \n",
    "            dev_loss, dev_recall = evaluate(model, dev_data, tokenizer)\n",
    "            dev_losses.append(dev_loss)\n",
    "            dev_recalls.append(dev_recall)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Batch {i//BATCH_SIZE}\")\n",
    "            print(f\"Train - Loss: {avg_train_loss:.4f}, Recall@1: {avg_train_recall:.4f}\")\n",
    "            print(f\"Dev   - Loss: {dev_loss:.4f}, Recall@1: {dev_recall:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    print(\"Training completed.\")\n",
    "    print(f\"Final Train - Loss: {sum(train_losses[-100:]) / 100:.4f}, Recall@1: {sum(train_recalls[-100:]) / 100:.4f}\")\n",
    "    print(f\"Final Dev   - Loss: {dev_losses[-1]:.4f}, Recall@1: {dev_recalls[-1]:.4f}\")\n",
    "    \n",
    "    return train_losses, train_recalls, dev_losses, dev_recalls, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prepared data from msmarco_train_data.json...\n",
      "Loaded 2833 examples.\n",
      "Loading prepared data from msmarco_dev_data.json...\n",
      "Loaded 71 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 1/355 [00:08<52:00,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0\n",
      "Train - Loss: 2.0767, Recall@1: 0.1250\n",
      "Dev   - Loss: 2.0854, Recall@1: 0.1984\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 2/355 [00:15<45:16,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1\n",
      "Train - Loss: 2.0801, Recall@1: 0.0625\n",
      "Dev   - Loss: 2.0820, Recall@1: 0.2004\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 3/355 [00:22<42:13,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2\n",
      "Train - Loss: 2.0817, Recall@1: 0.0833\n",
      "Dev   - Loss: 2.0771, Recall@1: 0.1409\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 4/355 [00:29<40:55,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 3\n",
      "Train - Loss: 2.0783, Recall@1: 0.0938\n",
      "Dev   - Loss: 2.0745, Recall@1: 0.1548\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 5/355 [00:36<41:57,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 4\n",
      "Train - Loss: 2.0775, Recall@1: 0.1000\n",
      "Dev   - Loss: 2.0728, Recall@1: 0.1667\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 6/355 [00:43<40:37,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 5\n",
      "Train - Loss: 2.0765, Recall@1: 0.1250\n",
      "Dev   - Loss: 2.0723, Recall@1: 0.1528\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 7/355 [00:50<41:12,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 6\n",
      "Train - Loss: 2.0749, Recall@1: 0.1071\n",
      "Dev   - Loss: 2.0723, Recall@1: 0.1409\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 8/355 [00:58<43:10,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 7\n",
      "Train - Loss: 2.0758, Recall@1: 0.1094\n",
      "Dev   - Loss: 2.0722, Recall@1: 0.1409\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 9/355 [01:04<39:51,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 8\n",
      "Train - Loss: 2.0740, Recall@1: 0.1250\n",
      "Dev   - Loss: 2.0723, Recall@1: 0.1409\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 10/355 [01:10<37:51,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 9\n",
      "Train - Loss: 2.0749, Recall@1: 0.1375\n",
      "Dev   - Loss: 2.0722, Recall@1: 0.1548\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 11/355 [01:16<37:13,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10\n",
      "Train - Loss: 2.0689, Recall@1: 0.1625\n",
      "Dev   - Loss: 2.0723, Recall@1: 0.1409\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 12/355 [01:23<37:20,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 11\n",
      "Train - Loss: 2.0687, Recall@1: 0.1625\n",
      "Dev   - Loss: 2.0725, Recall@1: 0.1548\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎         | 13/355 [01:29<36:10,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 12\n",
      "Train - Loss: 2.0679, Recall@1: 0.1750\n",
      "Dev   - Loss: 2.0702, Recall@1: 0.1687\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 14/355 [01:35<35:48,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 13\n",
      "Train - Loss: 2.0716, Recall@1: 0.1625\n",
      "Dev   - Loss: 2.0702, Recall@1: 0.1944\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 15/355 [01:41<35:11,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 14\n",
      "Train - Loss: 2.0727, Recall@1: 0.1625\n",
      "Dev   - Loss: 2.0743, Recall@1: 0.1944\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▍         | 16/355 [01:47<34:47,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 15\n",
      "Train - Loss: 2.0718, Recall@1: 0.1500\n",
      "Dev   - Loss: 2.0817, Recall@1: 0.1944\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▍         | 17/355 [01:57<41:11,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 16\n",
      "Train - Loss: 2.0651, Recall@1: 0.1875\n",
      "Dev   - Loss: 2.0909, Recall@1: 0.2103\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 18/355 [02:03<38:53,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 17\n",
      "Train - Loss: 2.0626, Recall@1: 0.1875\n",
      "Dev   - Loss: 2.0996, Recall@1: 0.1845\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 19/355 [02:12<42:13,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 18\n",
      "Train - Loss: 2.0596, Recall@1: 0.2125\n",
      "Dev   - Loss: 2.0930, Recall@1: 0.2123\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 20/355 [02:19<41:42,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 19\n",
      "Train - Loss: 2.0629, Recall@1: 0.2250\n",
      "Dev   - Loss: 2.0817, Recall@1: 0.2103\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 21/355 [02:26<40:49,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 20\n",
      "Train - Loss: 2.0652, Recall@1: 0.2250\n",
      "Dev   - Loss: 2.0720, Recall@1: 0.1806\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 22/355 [02:32<38:47,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 21\n",
      "Train - Loss: 2.0619, Recall@1: 0.2375\n",
      "Dev   - Loss: 2.0652, Recall@1: 0.1944\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▋         | 23/355 [02:39<38:02,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 22\n",
      "Train - Loss: 2.0657, Recall@1: 0.2125\n",
      "Dev   - Loss: 2.0540, Recall@1: 0.1944\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 24/355 [02:45<36:49,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 23\n",
      "Train - Loss: 2.0666, Recall@1: 0.2250\n",
      "Dev   - Loss: 2.0479, Recall@1: 0.1806\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 25/355 [02:53<37:50,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 24\n",
      "Train - Loss: 2.0540, Recall@1: 0.2375\n",
      "Dev   - Loss: 2.0459, Recall@1: 0.1667\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 26/355 [03:00<39:31,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 25\n",
      "Train - Loss: 2.0504, Recall@1: 0.2500\n",
      "Dev   - Loss: 2.0422, Recall@1: 0.1806\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 27/355 [03:07<38:34,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 26\n",
      "Train - Loss: 2.0516, Recall@1: 0.2500\n",
      "Dev   - Loss: 2.0390, Recall@1: 0.1806\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 28/355 [03:14<38:05,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 27\n",
      "Train - Loss: 2.0509, Recall@1: 0.2625\n",
      "Dev   - Loss: 2.0359, Recall@1: 0.1667\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 29/355 [03:20<36:55,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 28\n",
      "Train - Loss: 2.0508, Recall@1: 0.2500\n",
      "Dev   - Loss: 2.0338, Recall@1: 0.1687\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 30/355 [03:27<36:32,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 29\n",
      "Train - Loss: 2.0323, Recall@1: 0.2500\n",
      "Dev   - Loss: 2.0327, Recall@1: 0.1528\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▊         | 31/355 [03:34<37:09,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 30\n",
      "Train - Loss: 2.0306, Recall@1: 0.2125\n",
      "Dev   - Loss: 2.0294, Recall@1: 0.1250\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 32/355 [03:41<36:20,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 31\n",
      "Train - Loss: 2.0330, Recall@1: 0.2250\n",
      "Dev   - Loss: 2.0247, Recall@1: 0.1250\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 33/355 [03:47<35:26,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 32\n",
      "Train - Loss: 2.0305, Recall@1: 0.2500\n",
      "Dev   - Loss: 2.0177, Recall@1: 0.1250\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 34/355 [03:58<42:56,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 33\n",
      "Train - Loss: 2.0225, Recall@1: 0.2625\n",
      "Dev   - Loss: 2.0163, Recall@1: 0.1389\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 35/355 [04:05<40:19,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 34\n",
      "Train - Loss: 2.0353, Recall@1: 0.2500\n",
      "Dev   - Loss: 2.0087, Recall@1: 0.1548\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 36/355 [04:11<38:44,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 35\n",
      "Train - Loss: 2.0402, Recall@1: 0.2250\n",
      "Dev   - Loss: 2.0022, Recall@1: 0.1825\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 37/355 [04:18<37:19,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 36\n",
      "Train - Loss: 2.0338, Recall@1: 0.2250\n",
      "Dev   - Loss: 1.9936, Recall@1: 0.2242\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 38/355 [04:24<35:24,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 37\n",
      "Train - Loss: 2.0317, Recall@1: 0.2250\n",
      "Dev   - Loss: 1.9857, Recall@1: 0.2242\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 39/355 [04:30<34:55,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 38\n",
      "Train - Loss: 2.0329, Recall@1: 0.2000\n",
      "Dev   - Loss: 1.9781, Recall@1: 0.2401\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█▏        | 40/355 [04:36<33:29,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 39\n",
      "Train - Loss: 2.0407, Recall@1: 0.2000\n",
      "Dev   - Loss: 1.9725, Recall@1: 0.2540\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 41/355 [04:42<32:22,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 40\n",
      "Train - Loss: 2.0376, Recall@1: 0.2500\n",
      "Dev   - Loss: 1.9658, Recall@1: 0.2817\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 42/355 [04:48<32:02,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 41\n",
      "Train - Loss: 2.0136, Recall@1: 0.2500\n",
      "Dev   - Loss: 1.9541, Recall@1: 0.3095\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 43/355 [04:56<34:35,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 42\n",
      "Train - Loss: 1.9973, Recall@1: 0.2375\n",
      "Dev   - Loss: 1.9228, Recall@1: 0.3254\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 44/355 [05:02<33:42,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 43\n",
      "Train - Loss: 1.9957, Recall@1: 0.2250\n",
      "Dev   - Loss: 1.9214, Recall@1: 0.2540\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 45/355 [05:08<32:31,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 44\n",
      "Train - Loss: 1.9942, Recall@1: 0.2125\n",
      "Dev   - Loss: 1.9357, Recall@1: 0.2540\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 46/355 [05:14<31:58,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 45\n",
      "Train - Loss: 1.9819, Recall@1: 0.2500\n",
      "Dev   - Loss: 1.9508, Recall@1: 0.2540\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 47/355 [05:21<33:09,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 46\n",
      "Train - Loss: 1.9700, Recall@1: 0.2500\n",
      "Dev   - Loss: 1.9500, Recall@1: 0.2540\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 47/355 [05:23<35:21,  6.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# losses, recalls = train_and_evaluate()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_losses, train_recalls, dev_losses, dev_recalls, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiencoder_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[76], line 106\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m similarities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(query_embeddings, doc_embeddings\u001b[38;5;241m.\u001b[39mt())\n\u001b[1;32m    105\u001b[0m loss \u001b[38;5;241m=\u001b[39m in_batch_cross_entropy_loss(similarities)\n\u001b[0;32m--> 106\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    109\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# losses, recalls = train_and_evaluate()\n",
    "train_losses, train_recalls, dev_losses, dev_recalls, model = train_and_evaluate()\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'biencoder_model.pth')\n",
    "\n",
    "# Save everything else\n",
    "with open('train_losses.json', 'w') as f:\n",
    "    json.dump(train_losses, f)\n",
    "\n",
    "with open('train_recalls.json', 'w') as f:\n",
    "    json.dump(train_recalls, f)\n",
    "\n",
    "with open('dev_losses.json', 'w') as f:\n",
    "    json.dump(dev_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiencoder_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Open whatever is in the path\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/torch/serialization.py:1072\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1070\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1071\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1072\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m   1074\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1075\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1076\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/exa/lib/python3.12/site-packages/torch/serialization.py:480\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "path = \"biencoder_model.pth\"\n",
    "# Open whatever is in the path\n",
    "torch.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Constants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CORPUS_FRACTION = 0.01\n",
    "NUM_QUERIES = 1000\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "REPO_ID = \"charlieoneill/exa-int\"\n",
    "FILENAME = \"biencoder_model.pth\"\n",
    "\n",
    "class BiEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return F.normalize(outputs.pooler_output, p=2, dim=-1)\n",
    "\n",
    "def load_model(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found locally. Downloading from Hugging Face Hub: {REPO_ID}\")\n",
    "        try:\n",
    "            model_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME, token=\"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\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading model: {e}\")\n",
    "            print(\"Initializing a new model instead.\")\n",
    "            model = BiEncoder().to(DEVICE)\n",
    "            model.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "            return model\n",
    "\n",
    "def prepare_evaluation_data():\n",
    "    print(\"Preparing evaluation data...\")\n",
    "    \n",
    "    # Load datasets\n",
    "    corpus = load_dataset(\"mteb/msmarco-v2\", \"corpus\")['corpus']\n",
    "    queries = load_dataset(\"mteb/msmarco-v2\", \"queries\")['queries']\n",
    "    default = load_dataset(\"mteb/msmarco-v2\", \"default\", split=\"dev\")\n",
    "\n",
    "    # Sample corpus\n",
    "    corpus_sample_size = int(len(corpus) * CORPUS_FRACTION)\n",
    "    corpus_sample = corpus.shuffle(seed=RANDOM_SEED).select(range(corpus_sample_size))\n",
    "\n",
    "    if os.path.exists('corpus_id_to_index.json'):\n",
    "        print(\"Loading existing corpus ID to index mapping...\")\n",
    "        with open('corpus_id_to_index.json', 'r') as f:\n",
    "            corpus_id_to_index = json.load(f)\n",
    "    else:\n",
    "        print(\"Creating new corpus ID to index mapping...\")\n",
    "        corpus_id_to_index = {item['_id']: idx for idx, item in enumerate(tqdm(corpus_sample))}\n",
    "        with open('corpus_id_to_index.json', 'w') as f:\n",
    "            json.dump(corpus_id_to_index, f)\n",
    "\n",
    "    # Filter default to match sampled corpus\n",
    "    default_filtered = default.filter(lambda x: x['corpus-id'] in corpus_id_to_index)\n",
    "\n",
    "    # Select 1000 queries\n",
    "    NUM_QUERIES = min(1000, len(default_filtered)) \n",
    "    selected_queries = default_filtered.shuffle(seed=RANDOM_SEED).select(range(NUM_QUERIES))\n",
    "    \n",
    "    # Create query dataset\n",
    "    query_ids = set(selected_queries['query-id'])\n",
    "    queries_filtered = queries.filter(lambda x: x['_id'] in query_ids)\n",
    "    \n",
    "    return corpus_sample, queries_filtered, selected_queries, corpus_id_to_index\n",
    "\n",
    "def embed_texts(model, tokenizer, texts):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "        batch = texts[i:i+BATCH_SIZE]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        inputs.pop('token_type_ids', None)\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(**inputs).cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.concatenate(embeddings, axis=0)\n",
    "\n",
    "def save_embeddings_and_mapping(embeddings, id_to_index, texts, filename_prefix):\n",
    "    np.save(f\"{filename_prefix}_embeddings.npy\", embeddings)\n",
    "    mapping = {doc_id: {\"index\": idx, \"text\": texts[idx]} for doc_id, idx in id_to_index.items()}\n",
    "    with open(f\"{filename_prefix}_mapping.json\", \"w\") as f:\n",
    "        json.dump(mapping, f)\n",
    "\n",
    "def load_embeddings_and_mapping(filename_prefix):\n",
    "    embeddings = np.load(f\"{filename_prefix}_embeddings.npy\")\n",
    "    with open(f\"{filename_prefix}_mapping.json\", \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    return embeddings, mapping\n",
    "\n",
    "def calculate_recall_at_1(similarities, query_ids, corpus_ids, corpus_id_to_index):\n",
    "    top_indices = similarities.argmax(axis=1)\n",
    "    correct = 0\n",
    "    for i, query_id in enumerate(query_ids):\n",
    "        predicted_corpus_id = list(corpus_id_to_index.keys())[top_indices[i]]\n",
    "        if predicted_corpus_id == corpus_ids[i]:\n",
    "            correct += 1\n",
    "    return correct / len(query_ids)\n",
    "\n",
    "def main():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    model = load_model(\"biencoder_model.pth\")\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased')\n",
    "\n",
    "    if not os.path.exists(\"corpus_embeddings.npy\") or not os.path.exists(\"corpus_mapping.json\"):\n",
    "        corpus_sample, queries_filtered, selected_queries, corpus_id_to_index = prepare_evaluation_data()\n",
    "        \n",
    "        print(\"Embedding corpus...\")\n",
    "        corpus_embeddings = embed_texts(model, tokenizer, corpus_sample['text'])\n",
    "        save_embeddings_and_mapping(corpus_embeddings, corpus_id_to_index, corpus_sample['text'], \"corpus\")\n",
    "        \n",
    "        print(\"Saving query data...\")\n",
    "        with open(\"query_data.json\", \"w\") as f:\n",
    "            json.dump({\n",
    "                \"query_ids\": selected_queries['query-id'],\n",
    "                \"corpus_ids\": selected_queries['corpus-id'],\n",
    "                \"query_texts\": queries_filtered['text']\n",
    "            }, f)\n",
    "    else:\n",
    "        print(\"Loading pre-computed embeddings and mappings...\")\n",
    "        corpus_embeddings, corpus_mapping = load_embeddings_and_mapping(\"corpus\")\n",
    "        with open(\"query_data.json\", \"r\") as f:\n",
    "            query_data = json.load(f)\n",
    "\n",
    "    print(\"Embedding queries...\")\n",
    "    query_embeddings = embed_texts(model, tokenizer, query_data['query_texts'])\n",
    "\n",
    "    print(\"Calculating similarities...\")\n",
    "    similarities = np.dot(query_embeddings, corpus_embeddings.T)\n",
    "\n",
    "    print(\"Calculating recall@1...\")\n",
    "    recall_at_1 = calculate_recall_at_1(similarities, query_data['query_ids'], query_data['corpus_ids'], corpus_mapping)\n",
    "\n",
    "    print(f\"Recall@1: {recall_at_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found locally. Downloading from Hugging Face Hub: charlieoneill/exa-int\n",
      "Preparing evaluation data...\n",
      "Loading existing corpus ID to index mapping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 285328/285328 [00:00<00:00, 582722.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding corpus...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
